{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e18e5b3",
   "metadata": {},
   "source": [
    "Data was collected using my https://github.com/rbhughes/purr_petra FastAPI thing, which admittedly does a lot of opinionated \"Silver\" level data reconciliation before getting transformed to JSON. I will likely fork purr_petra into a simple CLI. To import the JSON files into Databricks volumes:\n",
    "\n",
    "```\n",
    "bryan@ichabod mac_bucket % for file in *_well.json; do\n",
    "  databricks fs cp \"$file\" dbfs:/Volumes/geodata/petra/well_raw/\n",
    "done\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3118738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../\")  # Go up one directory from notebooks/ to src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ecd285",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"json\").load(\"/Volumes/geodata/petra/well_raw/\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.transforms import string_to_iso_date, generate_hash, replace_10e30_with_null\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df_flat = df.select(\n",
    "    F.col(\"repo_id\"),\n",
    "    F.col(\"uwi.uwi\").alias(\"uwi\"),\n",
    "    F.col(\"uwi.wsn\").alias(\"wsn\"),\n",
    "    F.col(\"uwi.label\").alias(\"uwi_label\"),\n",
    "    F.col(\"uwi.sortname\").alias(\"sortname\"),\n",
    "    F.col(\"bhloc.lat\").alias(\"bottom_lat\"),\n",
    "    F.col(\"bhloc.lon\").alias(\"bottom_lon\"),\n",
    "    F.col(\"locat.congress\").alias(\"congress\"),\n",
    "    F.col(\"locat.lat\").alias(\"surface_lat\"),\n",
    "    F.col(\"locat.lon\").alias(\"surface_lon\"),\n",
    "    F.col(\"locat.x\").alias(\"surface_x\"),\n",
    "    F.col(\"locat.y\").alias(\"surface_y\"),\n",
    "    F.col(\"well.adddate\").alias(\"app_row_created\"),\n",
    "    F.col(\"well.chgdate\").alias(\"app_row_changed\"),\n",
    "    F.col(\"well.county\").alias(\"county\"),\n",
    "    F.col(\"well.elev_fid\").alias(\"elev_fid\"),\n",
    "    F.col(\"well.elev_zid\").alias(\"elev_zid\"),\n",
    "    F.col(\"well.fieldname\").alias(\"fieldname\"),\n",
    "    F.col(\"well.fmattd\").alias(\"fmattd\"),\n",
    "    F.col(\"well.histoper\").alias(\"histoper\"),\n",
    "    F.col(\"well.label\").alias(\"well_label\"),\n",
    "    F.col(\"well.leasename\").alias(\"leasename\"),\n",
    "    F.col(\"well.leasenumber\").alias(\"leasenumber\"),\n",
    "    F.col(\"well.operator\").alias(\"operator\"),\n",
    "    F.col(\"well.prodfm\").alias(\"prodfm\"),\n",
    "    F.col(\"well.remarks\").alias(\"remarks\"),\n",
    "    F.col(\"well.shortname\").alias(\"shortname\"),\n",
    "    F.col(\"well.state\").alias(\"state\"),\n",
    "    F.col(\"well.symbol\").alias(\"symbol\"),\n",
    "    F.col(\"well.symcode\").alias(\"symcode\"),\n",
    "    F.col(\"well.wellname\").alias(\"wellname\"),\n",
    "    F.col(\"zdata.aband_date\").alias(\"aband_date\"),\n",
    "    F.col(\"zdata.active_datum_value\").alias(\"active_datum_value\"),\n",
    "    F.col(\"zdata.comp_date\").alias(\"comp_date\"),\n",
    "    F.col(\"zdata.cumgas\").alias(\"cumgas\"),\n",
    "    F.col(\"zdata.cumoil\").alias(\"cumoil\"),\n",
    "    F.col(\"zdata.cumwtr\").alias(\"cumwtr\"),\n",
    "    F.col(\"zdata.elev_df\").alias(\"elev_df\"),\n",
    "    F.col(\"zdata.elev_gr\").alias(\"elev_gr\"),\n",
    "    F.col(\"zdata.elev_kb\").alias(\"elev_kb\"),\n",
    "    F.col(\"zdata.elev_seis\").alias(\"elev_seis\"),\n",
    "    F.col(\"zdata.last_act_date\").alias(\"last_act_date\"),\n",
    "    F.col(\"zdata.permit_date\").alias(\"permit_date\"),\n",
    "    F.col(\"zdata.rig_date\").alias(\"rig_date\"),\n",
    "    F.col(\"zdata.report_date\").alias(\"report_date\"),\n",
    "    F.col(\"zdata.spud_date\").alias(\"spud_date\"),\n",
    "    F.col(\"zdata.td\").alias(\"td\"),\n",
    "    F.col(\"zdata.whipstock\").alias(\"whipstock\"),\n",
    "    F.col(\"zdata.wrs_date\").alias(\"wrs_date\"),\n",
    "    F.col(\"zdata.wtrdepth\").alias(\"water_depth\"),\n",
    "    F.col(\"zflddef.active_datum\").alias(\"active_datum\"),\n",
    ")\n",
    "\n",
    "df_well = df_flat\n",
    "\n",
    "\n",
    "# enforce timestamp for dates\n",
    "for col_name in [\n",
    "    \"aband_date\",\n",
    "    \"comp_date\",\n",
    "    \"permit_date\",\n",
    "    \"report_date\",\n",
    "    \"spud_date\",\n",
    "    \"rig_date\",\n",
    "    \"wrs_date\",\n",
    "    \"app_row_created\",\n",
    "    \"app_row_changed\",\n",
    "]:\n",
    "    df_well = string_to_iso_date(df_well, col_name, col_name)\n",
    "\n",
    "\n",
    "# ensure real nulls\n",
    "for col_name in [\n",
    "    \"bottom_lat\",\n",
    "    \"bottom_lon\",\n",
    "    \"surface_lat\",\n",
    "    \"surface_lon\",\n",
    "    \"surface_x\",\n",
    "    \"surface_y\",\n",
    "    \"active_datum_value\",\n",
    "    \"cumgas\",\n",
    "    \"cumoil\",\n",
    "    \"cumwtr\",\n",
    "    \"elev_df\",\n",
    "    \"elev_gr\",\n",
    "    \"elev_kb\",\n",
    "    \"elev_seis\",\n",
    "    \"td\",\n",
    "    \"whipstock\",\n",
    "]:\n",
    "    df_well = replace_10e30_with_null(df_well, col_name, col_name)\n",
    "\n",
    "\n",
    "# add id hash\n",
    "id_columns = [\"repo_id\", \"uwi\"]\n",
    "df_well = generate_hash(df_well, \"id\", \"well\", *id_columns)\n",
    "\n",
    "\n",
    "display(df_well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b96d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT \n",
    "    surface_lat,\n",
    "    surface_lon,\n",
    "    ST_Point(surface_lon, surface_lat) as geometry_point\n",
    "FROM geodata.petra.well_bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "DELETE FROM geodata.petra.well_bronze;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2be75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.transforms import upsert_dataframe_to_table\n",
    "\n",
    "result = upsert_dataframe_to_table(df_well, \"geodata.petra.well_bronze\")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this in vscode might be possible by installing spark, sedona locally,\n",
    "# but they may never be as compatible as really running on the cluster. The\n",
    "# best plan is to run spatial stuff on databricks\n",
    "\n",
    "\n",
    "# from sedona.spark import SedonaContext\n",
    "# from sedona.sql.st_constructors import ST_Point\n",
    "\n",
    "# sedona = SedonaContext.create(spark)\n",
    "\n",
    "# df = spark.table(\"geodata.petra.well_bronze\")\n",
    "# df_with_point = df.withColumn(\"point_geom\", ST_Point(\"surface_lon\", \"surface_lat\"))\n",
    "\n",
    "# df_with_point.write.format(\"delta\").mode(\"overwrite\").option(\n",
    "#     \"overwriteSchema\", \"true\"\n",
    "# ).option(\"mergeSchema\", \"true\").saveAsTable(\"geodata.petra.well_bronze\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
